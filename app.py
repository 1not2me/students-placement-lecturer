# -*- coding: utf-8 -*-
import os
from flask import Flask, render_template, request, send_file
from markupsafe import Markup
import pandas as pd
import numpy as np
from io import BytesIO
from dataclasses import dataclass
from typing import Any, List, Optional

app = Flask(__name__)

# ---------- ××¦×‘ ×ª×—×–×•×§×” / ×¡×’×•×¨ ----------
@app.before_request
def maintenance_mode():
    """
    ×× ×‘××©×ª× ×™ ×¡×‘×™×‘×” ×™×© MAINTENANCE_MODE=1
    ×›×œ ×‘×§×©×” ×ª×—×–×™×¨ ×“×£ '×”××ª×¨ ×¡×’×•×¨'.
    ×œ×¤×ª×™×—×”: ×œ×©× ×•×ª ×œ-0 ××• ×œ×”×¡×™×¨ ××ª ×”××©×ª× ×”.
    """
    if os.getenv("MAINTENANCE_MODE", "0") == "1":
        html = """
        <html lang="he" dir="rtl">
        <head>
          <meta charset="utf-8">
          <title>×”××ª×¨ ×¡×’×•×¨</title>
          <style>
            body{
              font-family:system-ui,-apple-system,Segoe UI,Heebo,Arial;
              background:#f8fafc;
              display:flex;
              align-items:center;
              justify-content:center;
              height:100vh;
              margin:0;
              color:#0f172a;
            }
            .box{
              padding:2rem 2.4rem;
              border-radius:18px;
              background:#ffffff;
              box-shadow:0 18px 45px rgba(15,23,42,0.12);
              border:1px solid rgba(148,163,253,0.3);
              max-width:520px;
              text-align:center;
            }
            h1{
              margin:0 0 0.75rem;
              font-size:1.8rem;
            }
            p{
              margin:0;
              font-size:1rem;
              color:#4b5563;
            }
          </style>
        </head>
        <body>
          <div class="box">
            <h1>×”××ª×¨ ×›×¢×ª ×¡×’×•×¨ ×œ×ª×—×–×•×§×” ğŸ› ï¸</h1>
            <p>×× ×—× ×• ××‘×¦×¢×™× ×¢×“×›×•× ×™× ×‘××¢×¨×›×ª. ×× × × ×¡×• ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.</p>
          </div>
        </body>
        </html>
        """
        return Markup(html)

# ---------- ×§×‘×•×¢×™ ×¢××•×“×•×ª ××¤×©×¨×™×™× ----------

STU_COLS = {
    "id": ["×ª×–", "×ª\"×–", "××¡×¤×¨ ×–×”×•×ª", "id", "ID", "stu_id"],
    "first": ["×©× ×¤×¨×˜×™", "×¤×¨×˜×™", "first_name", "first", "stu_first"],
    "last": ["×©× ××©×¤×—×”", "××©×¤×—×”", "last_name", "last", "stu_last"],
    "city": ["×¢×™×¨ ××’×•×¨×™×", "×¢×™×¨ ×”×¡×˜×•×“× ×˜", "city", "stu_city"],
    "preferred_field": ["×ª×—×•× ××•×¢×“×£", "×ª×—×•× ×”×ª××—×•×ª ××•×¢×“×£", "×©×“×” ××•×¢×“×£", "pref_field", "preferred_field"],
    "special_req": ["×‘×§×©×•×ª ××™×•×—×“×•×ª ×¡×˜×•×“× ×˜", "×‘×§×©×•×ª ××™×•×—×“×•×ª", "special_req", "×“×¨×™×©×•×ª ××™×•×—×“×•×ª"],
}

SITE_COLS = {
    "name": ["×©× ××§×•× ×”×”×ª××—×•×ª", "×©× ××•×¡×“", "××•×¡×“", "site_name"],
    "field": ["×ª×—×•× ×”×ª××—×•×ª", "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“", "field", "site_field"],
    "city": ["×¢×™×¨ ×”××•×¡×“", "×¢×™×¨", "site_city"],
    "capacity": ["×§×™×‘×•×œ×ª", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ (1 ××• 2)", "capacity", "site_capacity"],
    "special_req": ["×‘×§×©×•×ª ××™×•×—×“×•×ª ×××•×¡×“", "×‘×§×©×•×ª ××™×•×—×“×•×ª", "site_special_req"],
    "supervisor": ["×©× ×”××“×¨×™×š", "×©× ××“×¨×™×š", "supervisor_name"],
}

# ---------- ××©×§×•×œ×•×ª ×‘×¨×™×¨×ª ××—×“×œ ----------

@dataclass
class Weights:
    field: float = 0.5
    geo: float = 0.25
    special: float = 0.15
    pref: float = 0.10

# ========= ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ =========

def read_any(uploaded) -> pd.DataFrame:
    filename = uploaded.filename.lower()
    if filename.endswith(".csv"):
        return pd.read_csv(uploaded)
    return pd.read_excel(uploaded)

def pick_col(df: pd.DataFrame, options: List[str]) -> Optional[str]:
    cols_lower = {c.lower(): c for c in df.columns}
    for opt in options:
        for c_low, c_real in cols_lower.items():
            if opt.lower() == c_low:
                return c_real
    for opt in options:
        for c_low, c_real in cols_lower.items():
            if opt.lower() in c_low:
                return c_real
    return None

def normalize_text(x: Any) -> str:
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return ""
    return str(x).strip()

# --- ×¡×˜×•×“× ×˜×™× ---
def resolve_students(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["stu_id"] = out[pick_col(out, STU_COLS["id"])]
    out["stu_first"] = out[pick_col(out, STU_COLS["first"])]
    out["stu_last"] = out[pick_col(out, STU_COLS["last"])]
    out["stu_city"] = out[pick_col(out, STU_COLS["city"])] if pick_col(out, STU_COLS["city"]) else ""
    out["stu_pref"] = out[pick_col(out, STU_COLS["preferred_field"])] if pick_col(out, STU_COLS["preferred_field"]) else ""
    out["stu_req"] = out[pick_col(out, STU_COLS["special_req"])] if pick_col(out, STU_COLS["special_req"]) else ""

    for c in ["stu_id", "stu_first", "stu_last", "stu_city", "stu_pref", "stu_req"]:
        out[c] = out[c].apply(normalize_text)
    return out

# --- ××ª×¨×™× ---
def resolve_sites(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["site_name"] = out[pick_col(out, SITE_COLS["name"])]
    out["site_field"] = out[pick_col(out, SITE_COLS["field"])]
    out["site_city"] = out[pick_col(out, SITE_COLS["city"])]

    cap_col = pick_col(out, SITE_COLS["capacity"])
    if cap_col:
        out["site_capacity"] = pd.to_numeric(out[cap_col], errors="coerce").fillna(1).astype(int)
    else:
        out["site_capacity"] = 1

    spec_col = pick_col(out, SITE_COLS["special_req"])
    out["site_req"] = out[spec_col] if spec_col else ""

    sup_col = pick_col(out, SITE_COLS["supervisor"])
    out["site_supervisor"] = out[sup_col] if sup_col else ""

    for c in ["site_name", "site_field", "site_city", "site_req", "site_supervisor"]:
        out[c] = out[c].apply(normalize_text)

    out["capacity_left"] = out["site_capacity"].copy()
    return out

# --- ×—×™×©×•×‘ ×¦×™×•×Ÿ ×•×”×ª×¤×œ×’×•×ª ---
def compute_score_with_explain(stu, site, W: Weights):
    parts = {}

    # ×”×ª×××ª ×ª×—×•×
    if stu["stu_pref"] and site["site_field"]:
        parts["×”×ª×××ª ×ª×—×•×"] = 100 if stu["stu_pref"] in site["site_field"] else 0
    else:
        parts["×”×ª×××ª ×ª×—×•×"] = 50

    # ××¨×—×§ / ×’×™××•×’×¨×¤×™×” (×›××Ÿ ×“××•×™Ö¾×œ×•×’×™×§×” ×¤×©×•×˜×”)
    if stu["stu_city"] and site["site_city"]:
        parts["××¨×—×§/×’×™××•×’×¨×¤×™×”"] = 100 if stu["stu_city"] == site["site_city"] else 40
    else:
        parts["××¨×—×§/×’×™××•×’×¨×¤×™×”"] = 60

    # ×‘×§×©×•×ª ××™×•×—×“×•×ª ××•×¡×“/×¡×˜×•×“× ×˜
    parts["×‘×§×©×•×ª ××™×•×—×“×•×ª"] = 100

    # ×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª (×›××Ÿ ×‘×’×¨×¡×” ×¤×©×•×˜×”)
    parts["×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª"] = 80

    score = (
        parts["×”×ª×××ª ×ª×—×•×"] * W.field +
        parts["××¨×—×§/×’×™××•×’×¨×¤×™×”"] * W.geo +
        parts["×‘×§×©×•×ª ××™×•×—×“×•×ª"] * W.special +
        parts["×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª"] * W.pref
    ) / 100.0 * 100

    return round(score), parts

# --- ××œ×’×•×¨×™×ª× ×©×™×‘×•×¥ ×—××“× ×™ ---
def greedy_match(students_df: pd.DataFrame, sites_df: pd.DataFrame, W: Weights) -> pd.DataFrame:
    results = []
    supervisor_count = {}  # ×¢×“ 2 ×¡×˜×•×“× ×˜×™× ×œ×›×œ ××“×¨×™×š (× ×™×ª×Ÿ ×œ×©× ×•×ª)

    for _, s in students_df.iterrows():
        cand = sites_df[sites_df["capacity_left"] > 0].copy()

        # ××™×Ÿ ×‘×›×œ×œ ××§×•××•×ª ×¤× ×•×™×™×
        if cand.empty:
            results.append({
                "×ª\"×– ×”×¡×˜×•×“× ×˜": s["stu_id"],
                "×©× ×¤×¨×˜×™": s["stu_first"],
                "×©× ××©×¤×—×”": s["stu_last"],
                "×©× ××§×•× ×”×”×ª××—×•×ª": "×œ× ×©×•×‘×¥",
                "×¢×™×¨ ×”××•×¡×“": "",
                "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": "",
                "×©× ×”××“×¨×™×š": "",
                "××—×•×– ×”×ª×××”": 0,
                "_expl": {
                    "×”×ª×××ª ×ª×—×•×": 0,
                    "××¨×—×§/×’×™××•×’×¨×¤×™×”": 0,
                    "×‘×§×©×•×ª ××™×•×—×“×•×ª": 0,
                    "×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª": 0
                }
            })
            continue

        # ××—×©×‘×™× ×¦×™×•×Ÿ ×œ×›×œ ××ª×¨
        def score_row(r):
            sc, parts = compute_score_with_explain(s, r, W)
            return pd.Series({"score": sc, "_parts": parts})

        cand[["score", "_parts"]] = cand.apply(score_row, axis=1)

        # ××¡× × ×™× ×œ×¤×™ ××’×‘×œ×ª ××“×¨×™×š (×¢×“ 2 ×¡×˜×•×“× ×˜×™× ×œ××©×œ)
        def allowed_supervisor(r):
            sup = r.get("×©× ×”××“×¨×™×š", "")
            return supervisor_count.get(sup, 0) < 2

        filtered = cand[cand.apply(allowed_supervisor, axis=1)]

        # ×× ××™×Ÿ ××ª×¨ ×œ××—×¨ ×¡×™× ×•×Ÿ â€“ ×œ×•×§×—×™× ××”××§×•×¨×™
        if filtered.empty:
            filtered = cand

        # ×‘×•×—×¨×™× ××ª ×”××ª×¨ ×¢× ×”×¦×™×•×Ÿ ×”×’×‘×•×”
        chosen = filtered.sort_values("score", ascending=False).iloc[0]
        idx = chosen.name

        # ××¢×“×›× ×™× ×§×™×‘×•×œ×ª
        sites_df.at[idx, "capacity_left"] -= 1

        # ××¢×“×›× ×™× ×¡×¤×™×¨×ª ×¡×˜×•×“× ×˜×™× ×œ××“×¨×™×š
        sup_name = chosen.get("×©× ×”××“×¨×™×š", "")
        supervisor_count[sup_name] = supervisor_count.get(sup_name, 0) + 1

        # ×©×•×¨×ª ×ª×•×¦××”
        results.append({
            "×ª\"×– ×”×¡×˜×•×“× ×˜": s["stu_id"],
            "×©× ×¤×¨×˜×™": s["stu_first"],
            "×©× ××©×¤×—×”": s["stu_last"],
            "×©× ××§×•× ×”×”×ª××—×•×ª": chosen["site_name"],
            "×¢×™×¨ ×”××•×¡×“": chosen["site_city"],
            "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": chosen["site_field"],
            "×©× ×”××“×¨×™×š": chosen.get("site_supervisor", ""),
            "××—×•×– ×”×ª×××”": chosen["score"],
            "_expl": chosen["_parts"]
        })

    return pd.DataFrame(results)

# ========= ×¢×–×¨ ×œ-XLSX =========

def df_to_xlsx_bytes(df: pd.DataFrame, sheet_name: str = "Sheet1") -> bytes:
    xlsx_io = BytesIO()
    with pd.ExcelWriter(xlsx_io, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name)
        workbook = writer.book
        worksheet = writer.sheets[sheet_name]

        # ×¢×™×¦×•×‘ ×¨××©×™ ×˜×‘×œ×”
        header_fmt = workbook.add_format({
            "bold": True,
            "bg_color": "#EEF2FF",
            "font_color": "#111827",
            "border": 1
        })
        for col_num, value in enumerate(df.columns.values):
            worksheet.write(0, col_num, value, header_fmt)

        # ×”×ª×××ª ×¨×•×—×‘ ×¢××•×“×•×ª
        for i, col in enumerate(df.columns):
            max_len = max([len(str(v)) for v in df[col]] + [len(col)]) + 2
            worksheet.set_column(i, i, max_len)

    xlsx_io.seek(0)
    return xlsx_io.getvalue()

# ========= ××©×ª× ×™× ×’×œ×•×‘×œ×™×™× =========
last_results_df: Optional[pd.DataFrame] = None
last_summary_df: Optional[pd.DataFrame] = None

# ========= ×¨××•×˜ ×¨××©×™ =========
@app.route("/", methods=["GET", "POST"])
def index():
    global last_results_df, last_summary_df

    context = {
        "results": None,
        "summary": None,
        "capacities": None,
        "expl_for_first": None,
        "explanations": None,
        "error": None
    }

    if request.method == "POST":
        students_file = request.files.get("students_file")
        sites_file = request.files.get("sites_file")

        if not students_file or not sites_file:
            context["error"] = "×™×© ×œ×”×¢×œ×•×ª ×’× ×§×•×‘×¥ ×¡×˜×•×“× ×˜×™× ×•×’× ×§×•×‘×¥ ××ª×¨×™ ×”×ª××—×•×ª."
            return render_template("index.html", **context)

        try:
            df_students_raw = read_any(students_file)
            df_sites_raw = read_any(sites_file)

            students = resolve_students(df_students_raw)
            sites = resolve_sites(df_sites_raw)

            base_df = greedy_match(students, sites, Weights())

            # ××™×•×Ÿ ×”×ª×•×¦××•×ª ×•×©××™×¨×” ×œ××©×ª× ×” ×’×œ×•×‘×œ×™
            base_sorted = base_df.sort_values("××—×•×– ×”×ª×××”", ascending=False).reset_index(drop=True)
            last_results_df = base_sorted.copy()

            # ×˜×‘×œ×ª ×ª×•×¦××•×ª ×œ×ª×¦×•×’×”
            df_show = pd.DataFrame({
                "××—×•×– ×”×ª×××”": base_sorted["××—×•×– ×”×ª×××”"].astype(int),
                "×©× ×”×¡×˜×•×“× ×˜/×™×ª": (base_sorted["×©× ×¤×¨×˜×™"].astype(str) + " " + base_sorted["×©× ××©×¤×—×”"].astype(str)).str.strip(),
                "×ª×¢×•×“×ª ×–×”×•×ª": base_sorted["×ª\"×– ×”×¡×˜×•×“× ×˜"],
                "×ª×—×•× ×”×ª××—×•×ª": base_sorted["×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“"],
                "×¢×™×¨ ×”××•×¡×“": base_sorted["×¢×™×¨ ×”××•×¡×“"],
                "×©× ××§×•× ×”×”×ª××—×•×ª": base_sorted["×©× ××§×•× ×”×”×ª××—×•×ª"],
                "×©× ×”××“×¨×™×š/×”": base_sorted["×©× ×”××“×¨×™×š"],
            })

            # ×˜×‘×œ×ª ×¡×™×›×•× ×œ××•×¡×“×•×ª
            summary_df = (
                base_df
                .groupby(["×©× ××§×•× ×”×”×ª××—×•×ª", "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“", "×©× ×”××“×¨×™×š"])
                .agg({
                    "×ª\"×– ×”×¡×˜×•×“× ×˜": "count",
                    "×©× ×¤×¨×˜×™": list,
                    "×©× ××©×¤×—×”": list
                }).reset_index()
            )
            summary_df.rename(columns={"×ª\"×– ×”×¡×˜×•×“× ×˜": "×›××” ×¡×˜×•×“× ×˜×™×"}, inplace=True)
            summary_df["×”××œ×¦×ª ×©×™×‘×•×¥"] = summary_df.apply(
                lambda row: " + ".join(
                    [f"{f} {l}" for f, l in zip(row["×©× ×¤×¨×˜×™"], row["×©× ××©×¤×—×”"])]
                ),
                axis=1
            )
            summary_df = summary_df[[
                "×©× ××§×•× ×”×”×ª××—×•×ª",
                "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“",
                "×©× ×”××“×¨×™×š",
                "×›××” ×¡×˜×•×“× ×˜×™×",
                "×”××œ×¦×ª ×©×™×‘×•×¥"
            ]]
            last_summary_df = summary_df.copy()

            # ×§×™×‘×•×œ×ª ××•×œ ×©×™×‘×•×¥ ×‘×¤×•×¢×œ
            caps = sites.groupby("site_name")["site_capacity"].sum().to_dict()
            assigned = base_df.groupby("×©× ××§×•× ×”×”×ª××—×•×ª")["×ª\"×– ×”×¡×˜×•×“× ×˜"].count().to_dict()
            cap_rows = []
            for site_name, capacity in caps.items():
                used = int(assigned.get(site_name, 0))
                cap_rows.append({
                    "×©× ××§×•× ×”×”×ª××—×•×ª": site_name,
                    "×§×™×‘×•×œ×ª": int(capacity),
                    "×©×•×‘×¦×• ×‘×¤×•×¢×œ": used,
                    "×™×ª×¨×”/×—×•×¡×¨": int(capacity - used)
